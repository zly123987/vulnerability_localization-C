import torch
from transformers import RobertaTokenizer, RobertaForSequenceClassification
from config import threshold
from utils.parse_java import parse_java



def load_model(model_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')
    model = RobertaForSequenceClassification.from_pretrained(model_path)

    # If you're using a GPU for inference
    model = model.to(device)
    return model, tokenizer, device

def inference_model_function(args):
    func, tokenizer, model, device, cve_description, index, all_length = args
    if func['comment']:
        func_body= func['comment']+'\n'+func['body']
    else:
        func_body= func['body']
    inputs = tokenizer.encode_plus(
        cve_description + "[SEP]" + func_body,  # You might need a separator depending on your data
        return_tensors="pt",
        max_length=512,  # Ensure this matches your training setup
        truncation=True,
        padding="max_length"
    )

    # Move tensors to the same device as the model
    inputs = {k: v.to(model.device) for k, v in inputs.items()}


    with torch.no_grad():  # Disable gradient calculation
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=-1)  # Convert logits to probabilities

        # Define your custom threshold

        # Since it's binary classification, assuming the positive class is the second one
        # Adjust the index if your positive class is at a different position
        positive_class_probabilities = probabilities[:, 1]
        
        # Determine predictions based on your custom threshold
        predictions = (positive_class_probabilities >= threshold).int()
        
    # predicted_class = predictions#.argmax(dim=-1).item()
    # print(f'Progress: {index}/{all_length}', '\r', end='', flush=True)
    # if predicted_class:
        # print('Predicted:', func['name'], func['file'])
    return func, str(positive_class_probabilities.item())
    # else:
        # return None, None


def inference_model(args):
    file_path, tokenizer, model, device, cve_description, index, all_length = args
    parsed = parse_java(file_path, file_path.split('/')[-1].replace('.java', ''))
    # Tokenize the input
    if len(parsed['classes']) == 0:
        body = parsed['body']
    else:
        body = parsed['classes'][0]['body']
    inputs = tokenizer.encode_plus(
        cve_description + "[SEP]" + body,  # You might need a separator depending on your data
        return_tensors="pt",
        max_length=512,  # Ensure this matches your training setup
        truncation=True,
        padding="max_length"
    )

    # Move tensors to the same device as the model
    inputs = {k: v.to(model.device) for k, v in inputs.items()}


    with torch.no_grad():  # Disable gradient calculation
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=-1)  # Convert logits to probabilities

        # Define your custom threshold
        threshold = 0.03

        # Since it's binary classification, assuming the positive class is the second one
        # Adjust the index if your positive class is at a different position
        positive_class_probabilities = probabilities[:, 1]

        # Determine predictions based on your custom threshold
        predictions = (positive_class_probabilities >= threshold).int()

    predicted_class = predictions#.argmax(dim=-1).item()
    print(f'Progress: {index}/{all_length}', '\r', end='', flush=True)
    if predicted_class:
        print('Predicted:', file_path)
        return file_path
    else:
        return None
